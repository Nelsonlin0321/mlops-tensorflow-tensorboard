{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST手写体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow 已经把 mnist 数据集集成在 examples 里面了\n",
    "# 在这里 import 数据输入的部分\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "\n",
    "tf.set_random_seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = mnist.train\n",
    "test_set = mnist.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard & `tf.summary`\n",
    "\n",
    "[前面](https://github.com/SherlockLiao/ai-class-intro/blob/master/tensorflow/course_0/tensorflow-basic.ipynb)已经给大家分享过如何使用`Tensorboard`将我们构建的计算图显示出来, 这里我们还要介绍它和`tf.summary`结合起来体现的更加强大的功能: 可视化训练. \n",
    "\n",
    "首先介绍一下`tf.summary`, 它能够收集训练过程中的各种`tensor`的信息并把它保存起来以供`Tensorboard`读取并展示. 按照下面的方法来使用它:\n",
    "\n",
    "### 构造`summary`\n",
    "- - -\n",
    "- 如果你想收集表示一个标量或者一个数的`tensor`的信息, 比如上面的`loss`\n",
    "```python\n",
    "loss_sum = tf.summary.scalar('loss', loss)\n",
    "```\n",
    "上面的语句就会告诉`Tensorflow`, 在运行过程中, 我要让`Tensorboard`显示误差的变化了\n",
    "- - -\n",
    "- 如果你想收集一个`tensor`的分布情况, 这个`tensor`可以是任意形状, 比如我们定义了一个`(784, 400)`的权重`w`\n",
    "```python\n",
    "w_hist = tf.summary.histogram('w_hist', w)\n",
    "```\n",
    "- - -\n",
    "- 如果你想收集一个4维的1-通道(灰度图), 3-通道(RGB), 4-通道(RGBA)的`tensor`的变化, 比如我们输出了一个`(1, 8, 8, 1)`的灰度图`image`\n",
    "```python\n",
    "image_sum = tf.summary.image('image', image)\n",
    "```\n",
    "- - -\n",
    "- 如果你想收集一个3维(batch, frame, channel), 2维(batch, frame)的变化, 比如我们输出了一个`(10, 50, 3)`的`tensor`:`audio`\n",
    "```python\n",
    "audio_sum = tf.summary.audio('audio', audio)\n",
    "```\n",
    "- - -\n",
    "在这次课程中, 我们暂时先使用`scalar`和`histogram`的`summary`, `image`和`audio`的`summary`将在之后的课程中介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重置计算图\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 重新定义占位符\n",
    "input_ph = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "label_ph = tf.placeholder(shape=(None, 10), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在, 我们需要重新构建前向神经网络, 为了简化代码, 我们在构造一个隐藏层以及它的参数的函数内部构造`tf.summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造权重, 用`truncated_normal`初始化\n",
    "def weight_variable(shape):\n",
    "    init = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "# 构造偏置, 用`0.1`初始化\n",
    "def bias_variable(shape):\n",
    "    init = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造添加`variable`的`summary`的函数\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        # 计算平均值\n",
    "        mean = tf.reduce_mean(var)\n",
    "        # 将平均值添加到`summary`中, 这是一个数值, 所以我们用`tf.summary.scalar`\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        \n",
    "        # 计算标准差\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        # 将标准差添加到`summary`中\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        \n",
    "        # 添加最大值,最小值`summary`\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        \n",
    "        # 添加这个变量分布情况的`summary`, 我们希望观察它的分布, 所以用`tf.summary.histogram`\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造一个隐藏层\n",
    "def hidden_layer(x, output_dim, scope='hidden_layer', act = tf.nn.relu, reuse=None):\n",
    "    # 获取输入的`depth`\n",
    "    input_dim = x.get_shape().as_list()[-1]\n",
    "    \n",
    "    with tf.name_scope(scope):\n",
    "        with tf.name_scope('weight'):\n",
    "            # 构造`weight`\n",
    "            weight = weight_variable([input_dim, output_dim])\n",
    "            # 添加`weight`的`summary`\n",
    "            variable_summaries(weight)\n",
    "            \n",
    "        with tf.name_scope('bias'):\n",
    "            # 构造`bias`\n",
    "            bias = bias_variable([output_dim])\n",
    "            # 添加`bias`的`summary`\n",
    "            variable_summaries(bias)\n",
    "            \n",
    "        with tf.name_scope('linear'):\n",
    "            # 计算`xw+b`\n",
    "            preact = tf.matmul(x, weight) + bias\n",
    "            # 添加激活层之前输出的分布情况到`summary`\n",
    "            tf.summary.histogram('pre_activation', preact)\n",
    "            \n",
    "        # 经过激活层`act`\n",
    "        output = act(preact)\n",
    "        # 添加激活后输出的分布情况到`summary`\n",
    "        tf.summary.histogram('output', output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造深度神经网络\n",
    "def DNN(x, output_depths, scope='DNN_with_sums', reuse=None):\n",
    "    with tf.name_scope(scope):\n",
    "        net = x\n",
    "        for i, output_depth in enumerate(output_depths):\n",
    "            net = hidden_layer(net, output_depth, scope='hidden%d' % (i + 1), reuse=reuse)\n",
    "        # 最后有一个分类层\n",
    "        net = hidden_layer(net, 10, scope='classification', act=tf.identity, reuse=reuse)\n",
    "        return net\n",
    "\n",
    "dnn_with_sums = DNN(input_ph, [400, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'cross_entropy/cross_entropy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy/accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    loss = tf.losses.softmax_cross_entropy(logits=dnn_with_sums, onehot_labels=label_ph)\n",
    "    tf.summary.scalar('cross_entropy', loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(dnn_with_sums, axis=-1), tf.argmax(label_ph, axis=-1)), dtype=tf.float32))\n",
    "    tf.summary.scalar('accuracy', acc)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    lr = 0.01\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出`summary`\n",
    "---\n",
    "`summary`是需要导出到外部文件的\n",
    "- 首先定义一个文件读写器\n",
    "```python\n",
    "summary_writer = tf.summary.FileWriter('summaries', sess.graph)\n",
    "```\n",
    "- - -\n",
    "- 然后在训练的过程中, 在你希望的时候运行一次`merged`或者是你之前自己定义的某个通过`summary`定义的`op`\n",
    "```python\n",
    "summaries = sess.run(merged, feed_dict={...})\n",
    "```\n",
    "- - -\n",
    "- 然后将这个`summaries`写入到`summari_writer`内\n",
    "```python\n",
    "summary_writer.add_summary(summaries, step)\n",
    "```\n",
    "注意`step`表示你当前训练的步数, 当然你也可以设定为其他你想要用的数值\n",
    "\n",
    "- - -\n",
    "- 最后关闭文件读写器\n",
    "```python\n",
    "summary_writer.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('test_summary/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('test_summary/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1000: train_loss: 0.363085 train_acc: 0.906250 test_loss: 0.363329 test_acc: 0.921875\n",
      "STEP 2000: train_loss: 0.198765 train_acc: 0.953125 test_loss: 0.342359 test_acc: 0.843750\n",
      "STEP 3000: train_loss: 0.084185 train_acc: 0.984375 test_loss: 0.204277 test_acc: 0.937500\n",
      "STEP 4000: train_loss: 0.056439 train_acc: 1.000000 test_loss: 0.090022 test_acc: 0.968750\n",
      "STEP 5000: train_loss: 0.155532 train_acc: 0.937500 test_loss: 0.197133 test_acc: 0.937500\n",
      "STEP 6000: train_loss: 0.066413 train_acc: 0.984375 test_loss: 0.154813 test_acc: 0.921875\n",
      "STEP 7000: train_loss: 0.122096 train_acc: 0.968750 test_loss: 0.154137 test_acc: 0.968750\n",
      "STEP 8000: train_loss: 0.083135 train_acc: 0.953125 test_loss: 0.066165 test_acc: 0.968750\n",
      "STEP 9000: train_loss: 0.096175 train_acc: 0.968750 test_loss: 0.175423 test_acc: 0.984375\n",
      "STEP 10000: train_loss: 0.122939 train_acc: 0.968750 test_loss: 0.084797 test_acc: 0.968750\n",
      "STEP 11000: train_loss: 0.051361 train_acc: 1.000000 test_loss: 0.122438 test_acc: 0.953125\n",
      "STEP 12000: train_loss: 0.036602 train_acc: 1.000000 test_loss: 0.098954 test_acc: 0.968750\n",
      "STEP 13000: train_loss: 0.031308 train_acc: 1.000000 test_loss: 0.046801 test_acc: 0.984375\n",
      "STEP 14000: train_loss: 0.031979 train_acc: 1.000000 test_loss: 0.043965 test_acc: 0.984375\n",
      "STEP 15000: train_loss: 0.069204 train_acc: 0.968750 test_loss: 0.088182 test_acc: 0.953125\n",
      "STEP 16000: train_loss: 0.019530 train_acc: 1.000000 test_loss: 0.171566 test_acc: 0.937500\n",
      "STEP 17000: train_loss: 0.027155 train_acc: 0.984375 test_loss: 0.011432 test_acc: 1.000000\n",
      "STEP 18000: train_loss: 0.014583 train_acc: 1.000000 test_loss: 0.125390 test_acc: 0.968750\n",
      "STEP 19000: train_loss: 0.012899 train_acc: 1.000000 test_loss: 0.074420 test_acc: 0.953125\n",
      "STEP 20000: train_loss: 0.019527 train_acc: 1.000000 test_loss: 0.094051 test_acc: 0.968750\n",
      "Train Done!\n",
      "------------------------------\n",
      "Train loss: 0.048358\n",
      "Train accuracy: 0.986764\n",
      "Test loss: 0.096270\n",
      "Test accuracy: 0.969300\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(20000):\n",
    "    images, labels = train_set.next_batch(batch_size)\n",
    "    sess.run(train_op, feed_dict={input_ph: images, label_ph: labels})\n",
    "    if e % 1000 == 999:\n",
    "        test_imgs, test_labels = test_set.next_batch(batch_size)\n",
    "        # 获取`train`数据的`summaries`以及`loss`, `acc`信息\n",
    "        sum_train, loss_train, acc_train = sess.run([merged, loss, acc], feed_dict={input_ph: images, label_ph: labels})\n",
    "        # 将`train`的`summaries`写入到`train_writer`中\n",
    "        train_writer.add_summary(sum_train, e)\n",
    "        # 获取`test`数据的`summaries`以及`loss`, `acc`信息\n",
    "        sum_test, loss_test, acc_test = sess.run([merged, loss, acc], feed_dict={input_ph: test_imgs, label_ph: test_labels})\n",
    "        # 将`test`的`summaries`写入到`test_writer`中\n",
    "        test_writer.add_summary(sum_test, e)\n",
    "        print('STEP {}: train_loss: {:.6f} train_acc: {:.6f} test_loss: {:.6f} test_acc: {:.6f}'.format(e + 1, loss_train, acc_train, loss_test, acc_test))\n",
    "\n",
    "# 关闭读写器\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "\n",
    "print('Train Done!')\n",
    "print('-'*30)\n",
    "\n",
    "# 计算所有训练样本的损失值以及正确率\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "for _ in range(train_set.num_examples // 100):\n",
    "    image, label = train_set.next_batch(100)\n",
    "    loss_train, acc_train = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    train_loss.append(loss_train)\n",
    "    train_acc.append(acc_train)\n",
    "\n",
    "print('Train loss: {:.6f}'.format(np.array(train_loss).mean()))\n",
    "print('Train accuracy: {:.6f}'.format(np.array(train_acc).mean()))\n",
    "\n",
    "# 计算所有测试样本的损失值以及正确率\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for _ in range(test_set.num_examples // 100):\n",
    "    image, label = test_set.next_batch(100)\n",
    "    loss_test, acc_test = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    test_loss.append(loss_test)\n",
    "    test_acc.append(acc_test)\n",
    "\n",
    "print('Test loss: {:.6f}'.format(np.array(test_loss).mean()))\n",
    "print('Test accuracy: {:.6f}'.format(np.array(test_acc).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打开`Tensorboard`\n",
    "\n",
    "\n",
    "\n",
    "在`test_summary`目录中输入以下命令\n",
    "```\n",
    "tensorboard --logdir=train:train/,test:test/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
